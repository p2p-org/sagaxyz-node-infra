apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  labels:
    app.kubernetes.io/component: controller
    app.kubernetes.io/name: prometheus-operator
    app.kubernetes.io/part-of: kube-prometheus
    app.kubernetes.io/version: 0.62.0
    prometheus: k8s
    role: alert-rules
  name: prometheus-operator-rules
  namespace: sagasrv-metrics
spec:
  groups:
  - name: prometheus-operator
    rules:
    - alert: PrometheusOperatorListErrors
      annotations:
        description: Errors while performing List operations in controller {% raw %}{{{% endraw %}$labels.controller{% raw %}}}{% endraw %} in {% raw %}{{{% endraw %}$labels.namespace{% raw %}}}{% endraw %} namespace.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus-operator/prometheusoperatorlisterrors
        summary: Errors while performing list operations in controller.
      expr: |
        (sum by (controller,namespace) (rate(prometheus_operator_list_operations_failed_total{job="prometheus-operator",namespace="sagasrv-metrics"}[10m])) / sum by (controller,namespace) (rate(prometheus_operator_list_operations_total{job="prometheus-operator",namespace="sagasrv-metrics"}[10m]))) > 0.4
      for: 15m
      labels:
        severity: warning
    - alert: PrometheusOperatorWatchErrors
      annotations:
        description: Errors while performing watch operations in controller {% raw %}{{{% endraw %}$labels.controller{% raw %}}}{% endraw %} in {% raw %}{{{% endraw %}$labels.namespace{% raw %}}}{% endraw %} namespace.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus-operator/prometheusoperatorwatcherrors
        summary: Errors while performing watch operations in controller.
      expr: |
        (sum by (controller,namespace) (rate(prometheus_operator_watch_operations_failed_total{job="prometheus-operator",namespace="sagasrv-metrics"}[5m])) / sum by (controller,namespace) (rate(prometheus_operator_watch_operations_total{job="prometheus-operator",namespace="sagasrv-metrics"}[5m]))) > 0.4
      for: 15m
      labels:
        severity: warning
    - alert: PrometheusOperatorSyncFailed
      annotations:
        description: Controller {% raw %}{{{% endraw %} $labels.controller {% raw %}}}{% endraw %} in {% raw %}{{{% endraw %} $labels.namespace {% raw %}}}{% endraw %} namespace fails to reconcile {% raw %}{{{% endraw %} $value {% raw %}}}{% endraw %} objects.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus-operator/prometheusoperatorsyncfailed
        summary: Last controller reconciliation failed
      expr: |
        min_over_time(prometheus_operator_syncs{status="failed",job="prometheus-operator",namespace="sagasrv-metrics"}[5m]) > 0
      for: 10m
      labels:
        severity: warning
    - alert: PrometheusOperatorReconcileErrors
      annotations:
        description: '{% raw %}{{{% endraw %} $value | humanizePercentage {% raw %}}}{% endraw %} of reconciling operations failed for {% raw %}{{{% endraw %} $labels.controller {% raw %}}}{% endraw %} controller in {% raw %}{{{% endraw %} $labels.namespace {% raw %}}}{% endraw %} namespace.'
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus-operator/prometheusoperatorreconcileerrors
        summary: Errors while reconciling controller.
      expr: |
        (sum by (controller,namespace) (rate(prometheus_operator_reconcile_errors_total{job="prometheus-operator",namespace="sagasrv-metrics"}[5m]))) / (sum by (controller,namespace) (rate(prometheus_operator_reconcile_operations_total{job="prometheus-operator",namespace="sagasrv-metrics"}[5m]))) > 0.1
      for: 10m
      labels:
        severity: warning
    - alert: PrometheusOperatorNodeLookupErrors
      annotations:
        description: Errors while reconciling Prometheus in {% raw %}{{{% endraw %} $labels.namespace {% raw %}}}{% endraw %} Namespace.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus-operator/prometheusoperatornodelookuperrors
        summary: Errors while reconciling Prometheus.
      expr: |
        rate(prometheus_operator_node_address_lookup_errors_total{job="prometheus-operator",namespace="sagasrv-metrics"}[5m]) > 0.1
      for: 10m
      labels:
        severity: warning
    - alert: PrometheusOperatorNotReady
      annotations:
        description: Prometheus operator in {% raw %}{{{% endraw %} $labels.namespace {% raw %}}}{% endraw %} namespace isn't ready to reconcile {% raw %}{{{% endraw %} $labels.controller {% raw %}}}{% endraw %} resources.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus-operator/prometheusoperatornotready
        summary: Prometheus operator not ready
      expr: |
        min by (controller,namespace) (max_over_time(prometheus_operator_ready{job="prometheus-operator",namespace="sagasrv-metrics"}[5m]) == 0)
      for: 5m
      labels:
        severity: warning
    - alert: PrometheusOperatorRejectedResources
      annotations:
        description: Prometheus operator in {% raw %}{{{% endraw %} $labels.namespace {% raw %}}}{% endraw %} namespace rejected {% raw %}{{{% endraw %} printf "%0.0f" $value {% raw %}}}{% endraw %} {% raw %}{{{% endraw %} $labels.controller {% raw %}}}{% endraw %}/{% raw %}{{{% endraw %} $labels.resource {% raw %}}}{% endraw %} resources.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus-operator/prometheusoperatorrejectedresources
        summary: Resources rejected by Prometheus operator
      expr: |
        min_over_time(prometheus_operator_managed_resources{state="rejected",job="prometheus-operator",namespace="sagasrv-metrics"}[5m]) > 0
      for: 5m
      labels:
        severity: warning
  - name: config-reloaders
    rules:
    - alert: ConfigReloaderSidecarErrors
      annotations:
        description: |-
          Errors encountered while the {% raw %}{{{% endraw %}$labels.pod{% raw %}}}{% endraw %} config-reloader sidecar attempts to sync config in {% raw %}{{{% endraw %}$labels.namespace{% raw %}}}{% endraw %} namespace.
          As a result, configuration for service running in {% raw %}{{{% endraw %}$labels.pod{% raw %}}}{% endraw %} may be stale and cannot be updated anymore.
        runbook_url: https://runbooks.prometheus-operator.dev/runbooks/prometheus-operator/configreloadersidecarerrors
        summary: config-reloader sidecar has not had a successful reload for 10m
      expr: |
        max_over_time(reloader_last_reload_successful{namespace=~".+"}[5m]) == 0
      for: 10m
      labels:
        severity: warning
